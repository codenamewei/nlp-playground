{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipeline of 3 main steps \n",
    "1. The text is preprocessed into a format that the model can understaend\n",
    "2. The preprocessed inputs are passed to the model \n",
    "3. The predictions of the model are post-processed\n",
    "\n",
    "# Available pipelines\n",
    "- sentiment-analysis\n",
    "- zero-shot-classification\n",
    "- text-generation\n",
    "- feature-extraction (get the vector representation of a text)\n",
    "- fill-mask\n",
    "- ner (named entity recognition)\n",
    "- question-answering\n",
    "- summarization\n",
    "- translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c896038f8c4b4cd88148b4c45ea8d356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e9ed3892b34f27ba34318e0bbf6506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b8e828ace743d8b91cfe2e9dddf017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99794dbddfa4838b3ab35f1e705a401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9982088208198547}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9982088208198547}, {'label': 'NEGATIVE', 'score': 0.9995144605636597}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9995144605636597}, {'label': 'NEGATIVE', 'score': 0.9995144605636597}]\n"
     ]
    }
   ],
   "source": [
    "# download and cached sentiment analysis model that has been fine-tuned in english\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "output = classifier(\"I've been waiting for a Hugging Face course my whole life\")\n",
    "\n",
    "print(output)\n",
    "\n",
    "output = classifier([\"I've been waiting for a Hugging Face course my whole life\", \"I hate this so much\"])\n",
    "                     \n",
    "print(output)\n",
    "                     \n",
    "output = classifier([\"I HATE THIS SO MUCH\", \"I hate this so much\"])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sequence': 'This is a netflix series about the Queens Gambit', 'labels': ['drama', 'computer', 'random'], 'scores': [0.9526435732841492, 0.03914288803935051, 0.008213580586016178]}, {'sequence': 'NVIDIA GPUs are commonly used for deep learning training', 'labels': ['computer', 'random', 'drama'], 'scores': [0.9674652218818665, 0.01740030199289322, 0.015134437009692192]}, {'sequence': 'This is a tumbler', 'labels': ['drama', 'computer', 'random'], 'scores': [0.6555460095405579, 0.19893909990787506, 0.14551487565040588]}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# zero-shot classification provide probability score for any list of labels with the data provided without training\n",
    "# so that dont need to rely on labels\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "output = classifier([\"This is a netflix series about the Queens Gambit\", \"NVIDIA GPUs are commonly used for deep learning training\", \"This is a tumbler\"], \n",
    "                   candidate_labels = [\n",
    "                       'drama', 'computer', 'random'\n",
    "                   ])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Hello World. \\xa0It\\'s also worth noting that this week\\'s \"Wizard of Oz\" has had a few slight alterations to the story and overall tone. \\xa0It\\'s a bit more like \"The Wizard of Oz,\" a version we'}]\n",
      "[{'generated_text': 'Hello World. \\xa0The name is derived from a French word for water, water, water and water. \\xa0There may be many meanings of the phrase \"water,\" and we might think of the word (and it is quite a simple name'}, {'generated_text': 'Hello World. \\xa0On the third and final day of the conference, I asked my colleagues who my main focus should be here because I knew they would have to be ready for that meeting and also had to accept that a lot of these kinds of'}]\n"
     ]
    }
   ],
   "source": [
    "# text generation include randomness, so its normal to not get the same results every time\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "prompt_text = \"Hello World. \"\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "output = generator(prompt_text)\n",
    "\n",
    "print(output)\n",
    "\n",
    "# you can control how many different sequences are generated with the argument\n",
    "# num_return_sequences\n",
    "\n",
    "# and the total length of the output text with the argument\n",
    "# max_length\n",
    "\n",
    "output = generator(prompt_text, num_return_sequences = 2, max_length = 50)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Christmas Eve is iced from apple juice for a healthy and easy to prepare holiday dinner with healthy options.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}, {'generated_text': 'Christmas Eve is iced with vanilla ice cream and vanilla ice cream. You can also just use something frozen, ice cream, or a bit more salt or coconut.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "prompt_text = \"Christmas Eve is \"\n",
    "\n",
    "generator = pipeline(\"text-generation\", model = \"distilgpt2\")\n",
    "\n",
    "output = generator(prompt_text, num_return_sequences = 2, max_length = 50)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Women is inherently human',\n",
       "  'score': 0.303619384765625,\n",
       "  'token': 22646,\n",
       "  'token_str': ' inherently'},\n",
       " {'sequence': 'Women is fundamentally human',\n",
       "  'score': 0.10839539021253586,\n",
       "  'token': 16894,\n",
       "  'token_str': ' fundamentally'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "\n",
    "# top_k: controls how many possibiltiies you want to be displayed\n",
    "# <mask> word also refer as mask token\n",
    "\n",
    "# different mask-filling model shave different mask tokens, its always good to verify the proper mask word when exploring other models\n",
    "\n",
    "unmasker(\"Women is <mask> human\", top_k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9976969957351685, 'word': 'Benny', 'start': 0, 'end': 5}, {'entity_group': 'LOC', 'score': 0.9990065693855286, 'word': 'Penang', 'start': 31, 'end': 37}, {'entity_group': 'LOC', 'score': 0.9998182654380798, 'word': 'Malaysia', 'start': 39, 'end': 47}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# this pipline works by extracting information from the provided context, it does not generate answer\n",
    "\n",
    "# when group_entities = True, it allows regroup together the parts of the sentence \n",
    "\n",
    "classifier = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "output = classifier(\"Benny stays in an orphanage at Penang, Malaysia\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ac65d871ac4e44b1ee84b40c5382ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb176a807d00407fb6b55c4e07ec3b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9472b35f9d564c7389f91a7e682a626e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d741149652194aebaf9e8a453fb3000b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ace7000ed24ce089fd2e1a1601c9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9885739684104919, 'start': 10, 'end': 15, 'answer': 'Intel'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"question-answering\")\n",
    "\n",
    "\n",
    "output = classifier(question = \"Where do i work\", context = \"Hi there. Intel is where I worked at. \")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c49bb15bf144ba8b36215929c508b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0591a06ffc044e77a097196118f5791c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e280c3aa004d94a81110bb734cd76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ccf0b5613d4b0a8886cacd57439e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b78246c5154f8094f3bcde3ee51334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/miniconda3/envs/hf-course/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" The Malay rulers are of the opinion that there is no need for the state of emergency to be extended after the Aug 1, 2021 deadline . This was after today's Special Discussion of the Malay Rulers with the Yang di-Pertuan Agong, held at Istana Negara .\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "#like with text gneration and summarization, you can specify a max_length or min_length for the result\n",
    "\n",
    "output = summarizer(\"\"\"KUALA LUMPUR: The Malay rulers are of the opinion that there is no need for the state of emergency to be extended after the Aug 1, 2021 deadline.\n",
    "\n",
    "This was after today's Special Discussion of the Malay Rulers with the Yang di-Pertuan Agong, held at Istana Negara, said Keeper of the Rulers' Seal, Tan Sri Syed Danial Syed Ahmad.\n",
    "\n",
    "He said in a statement today the Malay rulers, including Yang di-Pertuan Agong Al-Sultan Abdullah Ri'ayatuddin Mustafa Billah Shah, had expressed their opinions on several matters.\n",
    "\n",
    "These include the high daily number of Covid-19 cases, the country's worrying state of finance and economy, unstable political climate, disunity among the people, issues on well-being, unemployment, the education system, the inability of Muslims to perform religious obligations such as the Friday prayers as well as people of other religions being restricted from their religious activities.\n",
    "\n",
    "MORE NEWS\n",
    "Emergency and Sarawak state elections\n",
    "Sabah gov't supports State of Emergency move\n",
    "Reconvene by all means, but no more drama, please!\n",
    "PM: Malaysia still open for business despite State of Emergency\n",
    "\"The Malay rulers are of the same opinion on these matters: The people's lives and livelihood must be prioritised above all else. (Second) the vaccination process must be expedited by reducing bureaucracy so that the 80 per cent herd immunity target can be achieved.\n",
    "\n",
    "\"(Third) Covid-19 management programmes must be understood and supported by the public without raising any doubts or being perceived as a political agenda.\n",
    "\n",
    "\n",
    "\"(Fourth) the methods of handling the Covid-19 virus must be inclusive, involving various stakeholders while instilling the willing spirit to listen, learn, making adjustments and improvements and willingness to explore new methods, so that the people will be confident and give their support.\n",
    "\n",
    "\"(Fifth) the hot political climate must be curbed. (Sixth) it is important to have a stable government that has the support and confidence of the majority of the people.\n",
    "\n",
    "\"(Lastly), there is no necessity to place the country under a state of emergency after Aug 1, 2021,\" the statement read.\n",
    "\n",
    "The Malay rulers also defended the Agong's call earlier for Parliament to sit as soon as possible, saying that the check and balance mechanism between the executives, legislative and judiciary must be respected.\n",
    "\n",
    "They said this was to ensure transparent administrative works, integrity and accountability to the people, especially on matters involving finance and the country's spending.\n",
    "\n",
    "The rulers also called on state legislative assemblies to reconvene immediately by observing all Covid-19 standard operating procedure (SOP) to avoid further infection.\n",
    "\n",
    "\"Methods and procedures practiced by other countries when sitting (for parliament) proved that the chain of Covid-19 infection can be curbed and therefore, it is fitting that (these methods) be introduced and practiced in this country.\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c7ea904d8d432daebea54d1a9ba3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070669a8d3f745ea8332bedb3e69f804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6478ebbfed31423ba91d75f1e6159110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a7259d9dc94ffa92651e0b972c3ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/miniconda3/envs/hf-course/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'This course is produced by Hugging Face.'}]\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers[sentencepiece]\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# like with text gneration and summarization, you can specify a max_length or min_length for the result\n",
    "translator = pipeline(\"translation\", model = \"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "output = translator(\"Ce cours est produit par Hugging Face.\")\n",
    "\n",
    "\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
